{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e0db4c",
   "metadata": {},
   "source": [
    "# 🚀 Google Colab Faster-Whisper Audio Processing\n",
    "\n",
    "This notebook processes audio files using Faster-Whisper with GPU acceleration in Google Colab.\n",
    "\n",
    "**Benefits:**\n",
    "- 🟢 **FREE GPU acceleration** (10-20x faster than CPU)\n",
    "- 🟢 **No local installation** required\n",
    "- 🟢 **Batch processing** of multiple files\n",
    "- 🟢 **Same quality** as your local setup\n",
    "\n",
    "**Usage:**\n",
    "1. Upload your audio files to Google Drive\n",
    "2. Run all cells in order\n",
    "3. Download transcription results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c9a18",
   "metadata": {},
   "source": [
    "## 📦 Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64969e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install faster-whisper\n",
    "!pip install faster-whisper\n",
    "\n",
    "# Install audio processing libraries\n",
    "!pip install pydub\n",
    "\n",
    "print(\"✅ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d537d",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"✅ Google Drive mounted!\")\n",
    "print(\"📁 Your files are available at: /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c270d8a",
   "metadata": {},
   "source": [
    "## 🖥️ Step 3: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc641444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"🚀 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    device = \"cuda\"\n",
    "    compute_type = \"float16\"\n",
    "else:\n",
    "    print(\"⚠️  No GPU available - using CPU\")\n",
    "    device = \"cpu\"\n",
    "    compute_type = \"int8\"\n",
    "\n",
    "print(f\"🔧 Device: {device}\")\n",
    "print(f\"⚡ Compute type: {compute_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e385ea",
   "metadata": {},
   "source": [
    "## 🤖 Step 4: Initialize Faster-Whisper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3572269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Initialize model (load once, use many times)\n",
    "print(\"🔄 Loading Faster-Whisper model...\")\n",
    "model = WhisperModel(\n",
    "    \"small\",  # You can change to \"medium\" or \"large\" for better quality\n",
    "    device=device,\n",
    "    compute_type=compute_type\n",
    ")\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "def transcribe_audio_colab(file_path):\n",
    "    \"\"\"Transcribe audio using faster-whisper in Colab\"\"\"\n",
    "    try:\n",
    "        print(f\"🎵 Processing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Transcribe\n",
    "        segments, _ = model.transcribe(\n",
    "            file_path, \n",
    "            language=None,  # Auto language detection\n",
    "            beam_size=1,    # Faster\n",
    "            best_of=1,      # Faster\n",
    "            temperature=0   # More stable results\n",
    "        )\n",
    "        \n",
    "        # Collect text from segments\n",
    "        transcription = \"\"\n",
    "        for segment in segments:\n",
    "            transcription += segment.text + \" \"\n",
    "            \n",
    "        return transcription.strip(), None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "print(\"✅ Transcription function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb2a76",
   "metadata": {},
   "source": [
    "## 📂 Step 5: Configure File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE THESE PATHS FOR YOUR FILES\n",
    "source_dir = \"/content/drive/MyDrive/audio_files\"  # 👈 Change this to your audio folder\n",
    "output_dir = \"/content/output\"  # Local output folder\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📁 Source directory: {source_dir}\")\n",
    "print(f\"📁 Output directory: {output_dir}\")\n",
    "\n",
    "# Check if source directory exists\n",
    "if os.path.exists(source_dir):\n",
    "    print(\"✅ Source directory found!\")\n",
    "else:\n",
    "    print(\"❌ Source directory not found!\")\n",
    "    print(\"💡 Please update the source_dir path above to point to your audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7330e",
   "metadata": {},
   "source": [
    "## 🔍 Step 6: Find Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all audio files\n",
    "audio_extensions = ['*.m4a', '*.ogg', '*.wav', '*.mp3', '*.flac', '*.aac']\n",
    "audio_files = []\n",
    "\n",
    "for ext in audio_extensions:\n",
    "    pattern = os.path.join(source_dir, '**', ext)\n",
    "    files = glob.glob(pattern, recursive=True)\n",
    "    audio_files.extend(files)\n",
    "\n",
    "print(f\"📊 Found {len(audio_files)} audio files\")\n",
    "\n",
    "# Show first few files\n",
    "if audio_files:\n",
    "    print(\"\\n📋 First 5 files:\")\n",
    "    for i, file in enumerate(audio_files[:5]):\n",
    "        print(f\"  {i+1}. {os.path.basename(file)}\")\n",
    "    \n",
    "    if len(audio_files) > 5:\n",
    "        print(f\"  ... and {len(audio_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"❌ No audio files found!\")\n",
    "    print(\"💡 Make sure your audio files are in the source directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22542a2",
   "metadata": {},
   "source": [
    "## 🚀 Step 7: Process All Files (GPU Accelerated!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not audio_files:\n",
    "    print(\"❌ No audio files to process!\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🚀 STARTING GOOGLE COLAB BATCH PROCESSING\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📊 Total files: {len(audio_files)}\")\n",
    "    print(f\"🖥️  Device: {device}\")\n",
    "    print(f\"⚡ Compute type: {compute_type}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Process files\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\n[{i}/{len(audio_files)}] \", end=\"\")\n",
    "        \n",
    "        file_start = time.time()\n",
    "        \n",
    "        # Transcribe\n",
    "        transcription, error = transcribe_audio_colab(file_path)\n",
    "        \n",
    "        if error:\n",
    "            print(f\"❌ Error: {error}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "        if transcription and transcription.strip():\n",
    "            # Generate output filename\n",
    "            base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            output_file = os.path.join(output_dir, f\"{base_name}_COLAB_transcription.txt\")\n",
    "            \n",
    "            # Save transcription\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Source file: {file_path}\\n\")\n",
    "                f.write(\"Method: Faster-Whisper (Google Colab)\\n\")\n",
    "                f.write(f\"Device: {device}\\n\")\n",
    "                f.write(f\"Compute type: {compute_type}\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "                f.write(transcription)\n",
    "            \n",
    "            print(f\"✅ Saved: {os.path.basename(output_file)}\")\n",
    "            print(f\"📝 Text: {transcription[:100]}...\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(\"❌ Empty transcription\")\n",
    "            error_count += 1\n",
    "        \n",
    "        file_end = time.time()\n",
    "        print(f\"⏱️ Time: {file_end - file_start:.1f}s\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Final statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🏁 GOOGLE COLAB PROCESSING COMPLETED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✅ Successfully processed: {success_count}\")\n",
    "    print(f\"❌ Errors: {error_count}\")\n",
    "    print(f\"📊 Total files processed: {len(audio_files)}\")\n",
    "    print(f\"⏱️ Total time: {total_time:.1f}s\")\n",
    "    if success_count > 0:\n",
    "        print(f\"⚡ Average time per file: {total_time/len(audio_files):.1f}s\")\n",
    "    print(f\"📂 Output directory: {output_dir}\")\n",
    "    print(\"Files saved with '_COLAB_' prefix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd51995",
   "metadata": {},
   "source": [
    "## 📥 Step 8: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP file with all transcriptions\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "\n",
    "zip_filename = \"transcriptions_colab.zip\"\n",
    "zip_path = f\"/content/{zip_filename}\"\n",
    "\n",
    "# Create ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    for file in os.listdir(output_dir):\n",
    "        if file.endswith('_COLAB_transcription.txt'):\n",
    "            file_path = os.path.join(output_dir, file)\n",
    "            zipf.write(file_path, file)\n",
    "\n",
    "print(f\"📦 Created ZIP file: {zip_filename}\")\n",
    "print(f\"📊 ZIP file size: {os.path.getsize(zip_path) / 1024:.1f} KB\")\n",
    "\n",
    "# Download the ZIP file\n",
    "files.download(zip_path)\n",
    "print(\"✅ Download started! Check your Downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e000e1f",
   "metadata": {},
   "source": [
    "## 📊 Step 9: View Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample transcription\n",
    "transcription_files = [f for f in os.listdir(output_dir) if f.endswith('_COLAB_transcription.txt')]\n",
    "\n",
    "if transcription_files:\n",
    "    sample_file = os.path.join(output_dir, transcription_files[0])\n",
    "    \n",
    "    print(\"📋 SAMPLE TRANSCRIPTION:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(content[:500])  # First 500 characters\n",
    "        \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"📁 Total transcription files: {len(transcription_files)}\")\n",
    "else:\n",
    "    print(\"❌ No transcription files found\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
